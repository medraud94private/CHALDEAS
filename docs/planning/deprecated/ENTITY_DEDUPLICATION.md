# Entity Deduplication & Normalization

> **Status**: Active
> **Date**: 2026-01-26
> **Supersedes**: `ENTITY_NORMALIZATION.md`, `v2/ENTITY_MATCHING_STRATEGY.md`

---

## 1. í˜„í™© ë¶„ì„

### 1.1 ì¤‘ë³µ ê·œëª¨

```
Total persons: 286,609
With wikidata_id: 101,968
Unique wikidata_ids: 91,596
Potential duplicates: 10,372 (ë™ì¼ QID, ë‹¤ë¥¸ ë ˆì½”ë“œ)
```

### 1.2 ì¤‘ë³µ ì‚¬ë¡€ (ìƒìœ„)

| Wikidata QID | ì¤‘ë³µ ìˆ˜ | ì˜ˆì‹œ |
|--------------|--------|------|
| Q517 (Napoleon) | 23 | Napoleon, NapolÃ©on Bonaparte, Bonaparte, Napoleon the Great... |
| Q302 (Michelangelo) | 16 | - |
| Q692 (Shakespeare) | 13 | - |
| Q8409 (Alexander the Great) | 1 | ì •ìƒ (ë‹¨, ì˜¤íƒ€ ë ˆì½”ë“œ ë³„ë„ ì¡´ì¬) |

### 1.3 ì¤‘ë³µ ìœ í˜•

1. **QID ì¤‘ë³µ**: ë™ì¼ wikidata_id, ë‹¤ë¥¸ name â†’ ë³‘í•© í•„ìš”
2. **ì˜¤íƒ€/ë³€í˜•**: `Alex ander the Great` â†’ ì •ê·œí™” í•„ìš”
3. **QID ì—†ìŒ**: wikidata_id = NULLì¸ ë ˆì½”ë“œ ì¤‘ ì¤‘ë³µ â†’ íƒì§€ í•„ìš”

---

## 2. ê¸°ìˆ  ìŠ¤íƒ (í™•ì •)

| êµ¬ì„±ìš”ì†Œ | ì„ íƒ | ê·¼ê±° |
|---------|------|------|
| **Embedding** | `text-embedding-3-small` (OpenAI) | ì´ë¯¸ ë°±ì—”ë“œì—ì„œ ì‚¬ìš© ì¤‘, 1536 dim |
| **Vector Store** | pgvector | ì´ë¯¸ êµ¬ì¶•ë¨ |
| **LLM (1ì°¨)** | `gemma2:9b` (Ollama) | ë¡œì»¬, ë¬´ë£Œ, ê²€ì¦ìš© |
| **LLM (í´ë°±)** | `gpt-5.1-chat-latest` | ë³µì¡í•œ ì¼€ì´ìŠ¤ |
| **String Matching** | pg_trgm + rapidfuzz | PostgreSQL ë‚´ì¥ + Python |

---

## 3. ì¤‘ë³µ ì •ë¦¬ íŒŒì´í”„ë¼ì¸

### Phase 1: QID ê¸°ë°˜ ë³‘í•© (í™•ì‹¤í•œ ì¤‘ë³µ)

```python
def merge_by_wikidata_id():
    """ë™ì¼ wikidata_idë¥¼ ê°€ì§„ ë ˆì½”ë“œ ë³‘í•©"""

    duplicates = db.execute("""
        SELECT wikidata_id, array_agg(id) as ids, array_agg(name) as names
        FROM persons
        WHERE wikidata_id IS NOT NULL
        GROUP BY wikidata_id
        HAVING COUNT(*) > 1
    """)

    for dup in duplicates:
        # ëŒ€í‘œ ì´ë¦„ ì„ ì • (ê°€ì¥ ì¼ë°˜ì ì¸ ì˜ì–´ëª…)
        canonical = select_canonical_name(dup.names)
        primary_id = dup.ids[0]

        # ë‚˜ë¨¸ì§€ë¥¼ aliasë¡œ ì €ì¥
        for i, name in enumerate(dup.names):
            if name != canonical:
                save_alias(primary_id, name, alias_type='wikidata_variant')

        # ëŒ€í‘œ ë ˆì½”ë“œ ì—…ë°ì´íŠ¸
        update_person(primary_id, name=canonical)

        # ì¤‘ë³µ ë ˆì½”ë“œì˜ ê´€ê³„ ì´ì „ í›„ ì‚­ì œ
        for other_id in dup.ids[1:]:
            transfer_relationships(from_id=other_id, to_id=primary_id)
            delete_person(other_id)
```

**ì˜ˆìƒ ê²°ê³¼**: ~10,000ê°œ ë ˆì½”ë“œ ì •ë¦¬

### Phase 2: ì„ë² ë”© ê¸°ë°˜ í›„ë³´ íƒì§€ (QID ì—†ëŠ” ì¤‘ë³µ)

```python
def find_potential_duplicates():
    """wikidata_id ì—†ëŠ” ë ˆì½”ë“œ ì¤‘ ì¤‘ë³µ í›„ë³´ íƒì§€"""

    orphans = db.query(Person).filter(Person.wikidata_id == None).all()

    for person in orphans:
        # ì„ë² ë”© ìœ ì‚¬ë„ë¡œ í›„ë³´ ê²€ìƒ‰
        candidates = vector_store.search_similar(
            embed(person.name),
            content_type="person",
            min_similarity=0.85,
            limit=5
        )

        if candidates:
            # LLM ê²€ì¦
            result = verify_with_llm(person, candidates[0])
            if result.decision == "SAME":
                queue_for_merge(person.id, candidates[0].id, result.confidence)
```

### Phase 3: ìˆ˜ë™ ê²€í†  í

```sql
CREATE TABLE merge_queue (
    id SERIAL PRIMARY KEY,
    source_id INTEGER REFERENCES persons(id),
    target_id INTEGER REFERENCES persons(id),
    confidence FLOAT,
    method VARCHAR(50),  -- 'embedding', 'fuzzy', 'llm'
    status VARCHAR(20) DEFAULT 'pending',  -- 'pending', 'approved', 'rejected'
    reviewed_at TIMESTAMP
);
```

---

## 4. ì‹ ê·œ ì—”í‹°í‹° ë§¤ì¹­ íŒŒì´í”„ë¼ì¸

ìƒˆë¡œ ì¶”ì¶œëœ ì´ë¦„ì´ ê¸°ì¡´ DBì™€ ë§¤ì¹­ë˜ëŠ”ì§€ í™•ì¸:

```
[ì‹ ê·œ ì´ë¦„]
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Exact Match          â”‚ â”€â”€â”€ name ì¼ì¹˜ â†’ Done (conf: 1.0)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Alias Match          â”‚ â”€â”€â”€ entity_aliases í…Œì´ë¸” â†’ Done (conf: 0.95)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Wikidata QID Lookup  â”‚ â”€â”€â”€ ì´ë¦„ìœ¼ë¡œ Wikidata ê²€ìƒ‰ â†’ QID íšë“
â”‚                         â”‚     DBì— ë™ì¼ QID ìˆìœ¼ë©´ â†’ Done (conf: 0.98)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Embedding Similarity â”‚ â”€â”€â”€ text-embedding-3-small
â”‚    (pgvector)           â”‚     cosine > 0.9 â†’ í›„ë³´ ëª©ë¡ ìƒì„±
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. LLM Verification     â”‚ â”€â”€â”€ gemma2:9b (ë¡œì»¬)
â”‚                         â”‚     "ê°™ì€ ì¸ë¬¼ì¸ê°€?" â†’ ìµœì¢… íŒì •
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
[ë§¤ì¹­ ê²°ê³¼] â†’ ì„±ê³µ ì‹œ alias ì €ì¥ (í•™ìŠµ ë£¨í”„)
```

### 4.1 ê·œì¹™ ê¸°ë°˜ ì „ì²˜ë¦¬ (ìµœì†Œí™”)

```python
# íƒ€ì´í‹€ë§Œ ì œê±° (ìˆ˜ì‹ì–´ëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
TITLES = ['sir ', 'king ', 'queen ', 'lord ', 'lady ', 'prince ', 'princess ',
          'emperor ', 'empress ', 'pope ', 'saint ', 'st. ']

def normalize_title(name: str) -> str:
    """íƒ€ì´í‹€ë§Œ ì œê±°, ìˆ˜ì‹ì–´ëŠ” ìœ ì§€"""
    lower = name.lower().strip()
    for title in TITLES:
        if lower.startswith(title):
            return name[len(title):].strip()
    return name

# ì£¼ì˜: "the Great", "of Macedon" ê°™ì€ ìˆ˜ì‹ì–´ëŠ” ì œê±°í•˜ì§€ ì•ŠìŒ
# â†’ Wikidata aliasë¡œ ì²˜ë¦¬
```

### 4.2 í•™ìŠµ ë£¨í”„

```python
def learn_from_match(extracted_name: str, matched_id: int, confidence: float):
    """ì„±ê³µì  ë§¤ì¹­ì„ aliasë¡œ ì €ì¥"""

    # ì´ë¯¸ ìˆìœ¼ë©´ skip
    if alias_exists(matched_id, extracted_name):
        return

    # ìƒˆ alias ì €ì¥
    db.execute("""
        INSERT INTO entity_aliases (entity_type, entity_id, alias, alias_type, source, confidence)
        VALUES ('person', %s, %s, 'learned', 'auto_matched', %s)
    """, (matched_id, extracted_name, confidence))
```

---

## 5. ë°ì´í„° êµ¬ì¡°

### 5.1 entity_aliases í…Œì´ë¸”

```sql
CREATE TABLE entity_aliases (
    id SERIAL PRIMARY KEY,
    entity_type VARCHAR(50) NOT NULL,  -- 'person', 'location', 'event'
    entity_id INTEGER NOT NULL,
    alias VARCHAR(255) NOT NULL,
    alias_type VARCHAR(50),  -- 'wikidata', 'historical', 'learned', 'wikidata_variant'
    source VARCHAR(100),     -- 'wikidata', 'auto_matched', 'manual'
    confidence FLOAT DEFAULT 1.0,
    created_at TIMESTAMP DEFAULT NOW(),

    UNIQUE(entity_type, entity_id, alias)
);

CREATE INDEX idx_alias_lookup ON entity_aliases(LOWER(alias));
CREATE INDEX idx_alias_entity ON entity_aliases(entity_type, entity_id);
```

### 5.2 ëŒ€í‘œ ì´ë¦„ ì„ ì • ê¸°ì¤€

```python
def select_canonical_name(names: list[str]) -> str:
    """ëŒ€í‘œ ì´ë¦„ ì„ ì •"""

    scores = []
    for name in names:
        score = 0

        # ì˜ì–´ ì•ŒíŒŒë²³ë§Œ ìˆìœ¼ë©´ +10
        if name.isascii():
            score += 10

        # íŠ¹ìˆ˜ë¬¸ì ì—†ìœ¼ë©´ +5
        if name.replace(' ', '').isalnum():
            score += 5

        # ì ë‹¹í•œ ê¸¸ì´ (10-30ì) +5
        if 10 <= len(name) <= 30:
            score += 5

        # "the Great", "of ..." ê°™ì€ ìˆ˜ì‹ì–´ ìˆìœ¼ë©´ +3 (êµ¬ë¶„ë ¥)
        if ' the ' in name.lower() or ' of ' in name.lower():
            score += 3

        scores.append((name, score))

    return max(scores, key=lambda x: x[1])[0]
```

---

## 6. ì±… ë‹¨ìœ„ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

### 6.1 í•µì‹¬ ì›ì¹™

**"í•œ ê¶Œ ë³‘í•© â†’ í™•ì • â†’ ë‹¤ìŒ ê¶Œ"**

- ì „ì²´ DB ì •ë¦¬ ë¨¼ì €ê°€ ì•„ë‹˜
- ì±… í•œ ê¶Œì”© ì²˜ë¦¬í•˜ë©´ì„œ ì ì§„ì ìœ¼ë¡œ DB í’ˆì§ˆ ê°œì„ 
- Person, Location, Event ëª¨ë‘ ë™ì¼í•œ íŒŒì´í”„ë¼ì¸

### 6.2 ì±… ë‹¨ìœ„ ì²˜ë¦¬ íë¦„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ì±… 1ê¶Œ ì²˜ë¦¬                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  [1] ì±…ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ                                       â”‚
â”‚      - persons: ["Napoleon", "Josephine", "Wellington"]      â”‚
â”‚      - locations: ["Waterloo", "Paris", "Elba"]              â”‚
â”‚      - events: ["Battle of Waterloo", "Coronation"]          â”‚
â”‚                                                              â”‚
â”‚  [2] ê° ì—”í‹°í‹° ë§¤ì¹­ (EntityMatcher)                           â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚      â”‚ "Napoleon"                                 â”‚          â”‚
â”‚      â”‚   â†’ Exact? âœ—                              â”‚          â”‚
â”‚      â”‚   â†’ Alias? âœ—                              â”‚          â”‚
â”‚      â”‚   â†’ Wikidata? Q517 â†’ DBì— ìˆìŒ!           â”‚          â”‚
â”‚      â”‚   â†’ ë§¤ì¹­: person_id=26                    â”‚          â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                              â”‚
â”‚  [3] ë§¤ì¹­ ê²°ê³¼ ë¦¬ë·°                                           â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚      â”‚ MATCHED (wikidata):                       â”‚          â”‚
â”‚      â”‚   "Napoleon" â†’ Napoleon (id=26) [conf=0.98]â”‚          â”‚
â”‚      â”‚   "Josephine" â†’ JosÃ©phine (id=89) [0.95]  â”‚          â”‚
â”‚      â”‚                                            â”‚          â”‚
â”‚      â”‚ NEW (no match):                           â”‚          â”‚
â”‚      â”‚   "General Cambronne" â†’ ì‹ ê·œ ìƒì„± ì˜ˆì •     â”‚          â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                              â”‚
â”‚  [4] í™•ì • (Commit)                                           â”‚
â”‚      - ë§¤ì¹­ëœ ê²ƒ â†’ alias ì €ì¥ ("Napoleon" â†’ id=26)           â”‚
â”‚      - ì‹ ê·œ â†’ ë ˆì½”ë“œ ìƒì„± + embedding ì €ì¥                   â”‚
â”‚      - Source ì—°ê²°                                           â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                    [ë‹¤ìŒ ì±…ìœ¼ë¡œ]
```

### 6.3 ì ì§„ì  í’ˆì§ˆ ê°œì„ 

```
ì±… 1ê¶Œ ì²˜ë¦¬ í›„:
  - alias: "Napoleon" â†’ id=26
  - alias: "Josephine" â†’ id=89

ì±… 2ê¶Œ ì²˜ë¦¬ ì‹œ:
  - "NapolÃ©on Bonaparte" ë“±ì¥
  - Alias ë§¤ì¹­ ì‹¤íŒ¨ â†’ Wikidata Q517 â†’ id=26 ë§¤ì¹­!
  - alias ì¶”ê°€: "NapolÃ©on Bonaparte" â†’ id=26

ì±… 10ê¶Œ ì²˜ë¦¬ í›„:
  - Napoleon ê´€ë ¨ alias 10ê°œ ì¶•ì 
  - ì´í›„ ì±…ì—ì„œ ë¹ ë¥¸ ë§¤ì¹­
```

### 6.4 QID ê¸°ë°˜ ê¸°ì¡´ ì¤‘ë³µ ì²˜ë¦¬

ì±… ì²˜ë¦¬ ì¤‘ QID ì¤‘ë³µ ë°œê²¬ ì‹œ:

```python
# "NapolÃ©on" ë§¤ì¹­ ì‹œë„ â†’ Wikidata Q517
# DB ê²€ìƒ‰: Q517ì¸ ë ˆì½”ë“œê°€ ì—¬ëŸ¬ ê°œ?

existing = db.query(Person).filter(Person.wikidata_id == 'Q517').all()
# [id=26 "Napoleon", id=124769 "Napoleon Bonaparte", id=141296 "Napoleon the Great", ...]

if len(existing) > 1:
    # ìë™ ë³‘í•© íŠ¸ë¦¬ê±°
    primary = select_primary(existing)  # id=26 ì„ íƒ
    for other in existing[1:]:
        save_alias(primary.id, other.name)
        transfer_relationships(other.id, primary.id)
        delete_person(other.id)
```

â†’ **ì±… ì²˜ë¦¬í•˜ë©´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ê¸°ì¡´ ì¤‘ë³µë„ ì •ë¦¬ë¨**

### 6.5 EntityMatcher ì„œë¹„ìŠ¤

```python
# backend/app/services/entity_matching/matcher.py

class EntityMatcher:
    """ì±… import ì‹œ ì‚¬ìš©í•˜ëŠ” í†µí•© ë§¤ì¹­ ì„œë¹„ìŠ¤ (Person/Location/Event)"""

    def __init__(self, session, embedding_service, wikidata_client):
        self.session = session
        self.embedding = embedding_service
        self.wikidata = wikidata_client

    def match(self, entity_type: str, name: str, context: str = None) -> MatchResult:
        """
        í†µí•© 5ë‹¨ê³„ ë§¤ì¹­ íŒŒì´í”„ë¼ì¸

        Args:
            entity_type: 'person', 'location', 'event'
            name: ì—”í‹°í‹° ì´ë¦„
            context: ë¬¸ë§¥ (LLM ê²€ì¦ìš©)

        Returns:
            MatchResult(matched, entity_id, confidence, method)
        """
        model = self._get_model(entity_type)  # Person, Location, Event

        # 1. Exact match
        entity = self._exact_match(model, name)
        if entity:
            return MatchResult(True, entity.id, 1.0, 'exact')

        # 2. Alias match
        entity = self._alias_match(entity_type, name)
        if entity:
            return MatchResult(True, entity.id, 0.95, 'alias')

        # 3. Wikidata QID (+ ê¸°ì¡´ ì¤‘ë³µ ìë™ ë³‘í•©)
        qid = self.wikidata.search(name, entity_type)
        if qid:
            entities = self._find_by_qid(model, qid)
            if entities:
                if len(entities) > 1:
                    # ì¤‘ë³µ ë°œê²¬ â†’ ìë™ ë³‘í•©
                    primary = self._merge_duplicates(entity_type, entities)
                else:
                    primary = entities[0]
                self._learn_alias(entity_type, primary.id, name)
                return MatchResult(True, primary.id, 0.98, 'wikidata')

        # 4. Embedding similarity
        candidates = self._embedding_search(entity_type, name, limit=5, min_sim=0.85)
        if candidates:
            # 5. LLM verification
            best = self._llm_verify(entity_type, name, context, candidates)
            if best and best.confidence >= 0.9:
                self._learn_alias(entity_type, best.entity_id, name)
                return MatchResult(True, best.entity_id, best.confidence, 'llm')

        # No match â†’ create new
        new_entity = self._create_entity(entity_type, name, qid)
        return MatchResult(True, new_entity.id, 1.0, 'new')

    # í¸ì˜ ë©”ì„œë“œ
    def match_person(self, name, context=None):
        return self.match('person', name, context)

    def match_location(self, name, context=None):
        return self.match('location', name, context)

    def match_event(self, name, context=None):
        return self.match('event', name, context)
```

### 6.6 ì±… ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ (ëª¨ë“œ ì„ íƒ)

```python
# poc/scripts/process_book.py

"""
ì±… ì²˜ë¦¬ í†µí•© ìŠ¤í¬ë¦½íŠ¸

Usage:
    python process_book.py <book_path> --mode extract   # ì¶”ì¶œë§Œ â†’ JSON
    python process_book.py <book_path> --mode match     # ë§¤ì¹­ë§Œ â†’ DB
    python process_book.py <book_path> --mode full      # ì¶”ì¶œ â†’ ë§¤ì¹­ ìˆœì°¨
    python process_book.py <book_path> --mode match --dry-run  # ë§¤ì¹­ ë¦¬ë·°ë§Œ
"""

import argparse
from pathlib import Path

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('book_path', help='ì±… íŒŒì¼ ë˜ëŠ” extraction JSON ê²½ë¡œ')
    parser.add_argument('--mode', choices=['extract', 'match', 'full'], default='full')
    parser.add_argument('--dry-run', action='store_true', help='ë§¤ì¹­ ê²°ê³¼ ë¦¬ë·°ë§Œ (DB ë°˜ì˜ ì•ˆí•¨)')
    parser.add_argument('--output', help='ì¶”ì¶œ ê²°ê³¼ JSON ê²½ë¡œ (extract/full ëª¨ë“œ)')
    args = parser.parse_args()

    if args.mode == 'extract':
        # ì¶”ì¶œë§Œ: ì±… â†’ JSON
        result_path = extract_only(args.book_path, args.output)
        print(f"âœ“ Extracted: {result_path}")

    elif args.mode == 'match':
        # ë§¤ì¹­ë§Œ: ê¸°ì¡´ JSON â†’ DB
        match_only(args.book_path, dry_run=args.dry_run)

    elif args.mode == 'full':
        # ìˆœì°¨: ì¶”ì¶œ â†’ ë§¤ì¹­
        result_path = extract_only(args.book_path, args.output)
        print(f"âœ“ Extracted: {result_path}")
        match_only(result_path, dry_run=args.dry_run)


def extract_only(book_path: str, output_path: str = None) -> str:
    """
    ì±…ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ â†’ JSON ì €ì¥
    (ê¸°ì¡´ 8200 í¬íŠ¸ ì¶”ì¶œ ë¡œì§ í™œìš©)
    """
    # TODO: ê¸°ì¡´ ì¶”ì¶œ ë¡œì§ ì—°ë™
    extracted = extract_entities_from_book(book_path)

    if not output_path:
        output_path = Path(book_path).stem + "_extracted.json"

    save_json(extracted, output_path)
    return output_path


def match_only(json_path: str, dry_run: bool = False):
    """
    ì¶”ì¶œëœ JSON â†’ EntityMatcher â†’ DB
    """
    extracted = load_json(json_path)
    matcher = EntityMatcher(session, embedding_service, wikidata_client)

    results = {'matched': [], 'new': [], 'merged': []}

    for entity_type in ['persons', 'locations', 'events']:
        for entity in extracted.get(entity_type, []):
            result = matcher.match(
                entity_type.rstrip('s'),
                entity['name'],
                context=entity.get('context')
            )
            # ... (ì´ì „ ë¡œì§ê³¼ ë™ì¼)

    print_review(results)

    if not dry_run:
        commit_results(results)
        print(f"âœ“ Committed: {len(results['matched'])} matched, {len(results['new'])} new")
```

### 6.7 ëª¨ë“œë³„ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

```bash
# ì‹œë‚˜ë¦¬ì˜¤ 1: ì¶”ì¶œë§Œ í•˜ê³  ë‚˜ì¤‘ì— ë§¤ì¹­
python process_book.py book1.txt --mode extract
python process_book.py book2.txt --mode extract
# ... ë‚˜ì¤‘ì— ...
python process_book.py book1_extracted.json --mode match

# ì‹œë‚˜ë¦¬ì˜¤ 2: í•œë²ˆì— ë‹¤
python process_book.py book1.txt --mode full

# ì‹œë‚˜ë¦¬ì˜¤ 3: ë§¤ì¹­ ì „ ë¦¬ë·°
python process_book.py book1_extracted.json --mode match --dry-run
# ê²°ê³¼ í™•ì¸ í›„
python process_book.py book1_extracted.json --mode match
```

---

## 7. 8200 ì„œë²„ í™•ì¥ (Book Extractor í†µí•©)

### 7.1 ê°œìš”

ê¸°ì¡´ `tools/book_extractor/server.py` (8200 í¬íŠ¸)ì— ë§¤ì¹­ ê¸°ëŠ¥ ì¶”ê°€.
ìƒˆ ì±… â†’ 8200ì— ë„£ê¸°ë§Œ í•˜ë©´ ì¶”ì¶œ â†’ ë§¤ì¹­ â†’ DB ë°˜ì˜ê¹Œì§€ ì²˜ë¦¬.

### 7.2 ê¸°ì¡´ API (ì¶”ì¶œ)

```
/api/books              ì±… ëª©ë¡
/api/extract/*          ì¶”ì¶œ ì‹œì‘/ì·¨ì†Œ/ìƒíƒœ
/api/queue/*            í ê´€ë¦¬
/api/results/*          ì¶”ì¶œ ê²°ê³¼ (JSON)
/api/zim/*              ZIM íŒŒì¼ ì ‘ê·¼
/api/models             ëª¨ë¸ ì„ íƒ
/api/speed              ì†ë„ ëª¨ë“œ
```

### 7.3 ì¶”ê°€ API (ë§¤ì¹­)

```python
# tools/book_extractor/server.py ì— ì¶”ê°€

# â”€â”€â”€ ë§¤ì¹­ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.post("/api/match/start/{book_id}")
async def start_matching(book_id: str, background_tasks: BackgroundTasks):
    """
    ì¶”ì¶œ ì™„ë£Œëœ ì±…ì˜ ë§¤ì¹­ ì‹œì‘
    - EntityMatcherë¡œ DB ë§¤ì¹­
    - ê²°ê³¼ë¥¼ match_resultsì— ì €ì¥
    """

@app.get("/api/match/status/{book_id}")
async def get_match_status(book_id: str):
    """ë§¤ì¹­ ì§„í–‰ë¥ """

@app.get("/api/match/results/{book_id}")
async def get_match_results(book_id: str):
    """
    ë§¤ì¹­ ê²°ê³¼ ì¡°íšŒ (ë¦¬ë·°ìš©)
    Returns:
        {
            "matched": [...],   # ê¸°ì¡´ ì—”í‹°í‹°ì™€ ë§¤ì¹­ë¨
            "new": [...],       # ì‹ ê·œ ìƒì„± ì˜ˆì •
            "merged": [...]     # QID ì¤‘ë³µ ë³‘í•©ë¨
        }
    """

@app.post("/api/match/confirm/{book_id}")
async def confirm_matches(book_id: str, decisions: MatchDecisions):
    """
    ë§¤ì¹­ í™•ì •
    - accept: alias ì €ì¥ + source ì—°ê²°
    - reject: ìŠ¤í‚µ
    - create: ìƒˆ ì—”í‹°í‹° ìƒì„±
    """

# â”€â”€â”€ ì¤‘ë³µ í˜„í™© API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.get("/api/duplicates/status")
async def get_duplicate_status():
    """
    DB ì¤‘ë³µ í˜„í™©
    Returns:
        {
            "total_duplicates": 10372,
            "merged": 2127,
            "remaining": 8245,
            "recent_merges": [...]
        }
    """

# â”€â”€â”€ ìë™í™” ì˜µì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.post("/api/queue/settings")
async def update_queue_settings(settings: QueueSettings):
    """
    í ì„¤ì • ë³€ê²½
    - auto_match: bool  # ì¶”ì¶œ ì™„ë£Œ í›„ ìë™ ë§¤ì¹­ ì‹œì‘
    - auto_confirm_threshold: float  # ì´ confidence ì´ìƒì´ë©´ ìë™ í™•ì • (0.95)
    """
```

### 7.4 UI í™•ì¥ (8200 í”„ë¡ íŠ¸)

ê¸°ì¡´ HTMLì— ë§¤ì¹­ íƒ­ ì¶”ê°€:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“š Book Extractor                                          â”‚
â”‚  [Queue] [Books] [Results] [Matching âœ¨] [Duplicates âœ¨]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
```

#### Matching íƒ­

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“– Le Morte d'Arthur - Entity Matching                     â”‚
â”‚                                                             â”‚
â”‚  Status: âœ… Extracted â†’ ğŸ”„ Matching...                      â”‚
â”‚                                                             â”‚
â”‚  [Persons â–¼] [Locations] [Events]                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”€â”€ MATCHED (42) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ "King Arthur" â†’ Arthur, King (id=156)             â”‚     â”‚
â”‚  â”‚ Method: exact | Confidence: 1.0                   â”‚     â”‚
â”‚  â”‚ [âœ“] [âœ—]                                           â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                             â”‚
â”‚  â”€â”€ NEW (8) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ "Sir Bedivere" â†’ ì‹ ê·œ ìƒì„±                        â”‚     â”‚
â”‚  â”‚ Wikidata: Q786382                                 â”‚     â”‚
â”‚  â”‚ [Create] [Link] [Skip]                            â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [Auto-confirm high confidence] [Confirm All] [Skip All]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Duplicates íƒ­

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ”„ Duplicate Status                                        â”‚
â”‚                                                             â”‚
â”‚  Before: 10,372 â”‚ Merged: 2,127 â”‚ Remaining: 8,245         â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 20%                              â”‚
â”‚                                                             â”‚
â”‚  Recent Merges:                                            â”‚
â”‚  â€¢ Napoleon: 23 â†’ 1                                        â”‚
â”‚  â€¢ Shakespeare: 13 â†’ 1                                     â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.5 ì›Œí¬í”Œë¡œìš°

```
[ìƒˆ ì±… ì¶”ê°€]
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8200 ì„œë²„   â”‚
â”‚ Queue íƒ­    â”‚â”€â”€â†’ [Start Queue]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼ ì¶”ì¶œ ì™„ë£Œ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Matching íƒ­ â”‚â”€â”€â†’ [Start Matching] ë˜ëŠ” auto_match=true
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼ ë§¤ì¹­ ì™„ë£Œ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ë¦¬ë·° & í™•ì • â”‚â”€â”€â†’ [Confirm] ë˜ëŠ” auto_confirm (0.95+)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
[DB ë°˜ì˜ + Alias ì €ì¥]
```

---

## 8. ì‹¤í–‰ ê³„íš

| Phase | ì‘ì—… | ë¹„ê³  |
|-------|------|------|
| **1** | entity_aliases í…Œì´ë¸” ìƒì„± | DB ë§ˆì´ê·¸ë ˆì´ì…˜ |
| **2** | EntityMatcher ì„œë¹„ìŠ¤ êµ¬í˜„ | `tools/book_extractor/` ë‚´ë¶€ |
| **3** | 8200 ì„œë²„ API ì¶”ê°€ | `/api/match/*`, `/api/duplicates/*` |
| **4** | 8200 UI í™•ì¥ | Matching íƒ­, Duplicates íƒ­ |
| **5** | ì²« ë²ˆì§¸ ì±… ì²˜ë¦¬ | ì¶”ì¶œ â†’ ë§¤ì¹­ â†’ í™•ì • |
| **6** | ë°˜ë³µ | ì ì§„ì  í’ˆì§ˆ ê°œì„  |

â†’ **QID ì¤‘ë³µ ë³‘í•©ì€ ì±… ì²˜ë¦¬ ì¤‘ ìë™ìœ¼ë¡œ ë°œìƒ** (ë³„ë„ Phase ë¶ˆí•„ìš”)

---

## 9. ì„±ê³µ ì§€í‘œ

| ì§€í‘œ | í˜„ì¬ | ëª©í‘œ |
|------|------|------|
| ì¤‘ë³µ QID ë ˆì½”ë“œ | 10,372 | 0 |
| Alias ì»¤ë²„ë¦¬ì§€ | 0% | 90%+ |
| ì‹ ê·œ ë§¤ì¹­ ì •í™•ë„ | - | 95%+ |
| LLM í˜¸ì¶œ ë¹„ìœ¨ | - | <20% |

---

## 10. êµ¬í˜„ íŒŒì¼

```
# DB ë§ˆì´ê·¸ë ˆì´ì…˜
backend/alembic/versions/xxx_add_entity_aliases.py

# 8200 ì„œë²„ í™•ì¥ (tools/book_extractor/)
tools/book_extractor/
â”œâ”€â”€ server.py                   # ê¸°ì¡´ + ë§¤ì¹­ API ì¶”ê°€
â”œâ”€â”€ entity_matcher.py           # EntityMatcher ì„œë¹„ìŠ¤ (ì‹ ê·œ)
â”œâ”€â”€ wikidata_client.py          # Wikidata API (ì‹ ê·œ)
â”œâ”€â”€ llm_verifier.py             # LLM ê²€ì¦ (ì‹ ê·œ)
â””â”€â”€ static/
    â””â”€â”€ index.html              # ê¸°ì¡´ UI + Matching/Duplicates íƒ­

# ëª¨ë¸ (ë©”ì¸ ë°±ì—”ë“œì—ì„œ import)
backend/app/models/entity_alias.py
```

---

## 11. íê¸° ë¬¸ì„œ

ë‹¤ìŒ ë¬¸ì„œëŠ” ì´ ë¬¸ì„œë¡œ ëŒ€ì²´ë˜ì–´ ì‚­ì œë¨:
- ~~`docs/planning/ENTITY_NORMALIZATION.md`~~ (ì‚­ì œë¨)
- ~~`docs/planning/v2/ENTITY_MATCHING_STRATEGY.md`~~ (ì‚­ì œë¨)
